postgres=# COPY table_name TO '/path/to/file.csv' WITH CSV HEADER;
postgres=# COPY table_name FROM '/path/to/file.csv' WITH CSV HEADER;
postgres=# COPY employees TO '/tmp/employees.txt' WITH DELIMITER '|' NULL 'N/A' CSV HEADER;
postgres=# COPY employees(first_name, last_name, email) FROM '/tmp/new_employees.csv' WITH CSV HEADER;
postgres=# COPY (SELECT * FROM employees WHERE department = 'IT') TO '/tmp/it_employees.csv' WITH CSV HEADER;

postgres=# COPY products TO '/tmp/products.csv' WITH CSV HEADER;
postgres=# COPY customers TO '/tmp/customers.csv' WITH CSV HEADER DELIMITER ';' QUOTE '"';

postgres=# COPY orders TO '/tmp/orders.csv' WITH CSV HEADER FORCE_QUOTE (order_date);
postgres=# COPY products FROM '/tmp/products.csv' WITH CSV HEADER;

Import with error handling
postgres=# COPY products FROM '/tmp/products_with_errors.csv' WITH CSV HEADER ON_ERROR IGNORE;

Import with specific encoding
postgres=# COPY products FROM '/tmp/products_utf8.csv' WITH CSV HEADER ENCODING 'UTF8';

Handle embedded commas and quotes
postgres=# COPY customer_feedback TO '/tmp/feedback.csv' WITH CSV HEADER DELIMITER ',' QUOTE '"' ESCAPE '"';

Custom NULL representation
postgres=# COPY sales_data FROM '/tmp/sales.csv' WITH CSV HEADER NULL 'NULL';

3. pg_dump and pg_restore
Backup database to SQL file
pg_dump -h localhost -U burkhan -d postgre > backup.sql
Compressed custom format backup
pg_dump -h localhost -U burkhan -d postgre -Fc > backup.dump
Backup specific tables
pg_dump -h localhost -U user -d postgre -t employees -t departments > tables_backup.sql

Restore from custom format
$ pg_restore -h localhost -U username -d target_database backup.dump

Restore to a new database
$ createdb new_database
pg_restore -h localhost -U user -d new_database backup.dump

Restore specific tables
pg_restore -h localhost -U user -d postgre -t employees backup.dump

Parallel restore
pg_restore -h localhost -U user -d postgre -j 4 backup.dump

Schema-only backup
pg_dump -h localhost -U user -d postgre -s > schema_only.sql

Data-only backup
pg_dump -h localhost -U user -d postgre -a > data_only.sql

Exclude specific tables
pg_dump -h localhost -U user -d postgre -T log_table -T temp_data > backup_without_logs.sql

Full cluster backup
$ pg_dumpall -h localhost -U postgres > full_cluster_backup.sql

Full database backup with all objects
$ pg_dump -h localhost -U username -d production_db -Fc --verbose > full_production_backup.dump

Backup with ownership
pg_dump -h localhost -U user -d postgre -Fc -O > backup_with_ownership.dump

4. Incremental Backups (WAL)

Enable WAL archiving
postgres=# archive_mode = on
postgres=# archive_command = 'cp %p /backup/wal/%f'
postgres=# wal_level = replica

Create base backup
$ pg_basebackup -h localhost -U replication_user -D /backup/base -Ft -z -P
$ pg_basebackup -h localhost -U replication_user -D /backup/base -x -P

Force WAL segment switch
postgres=# SELECT pg_switch_wal();

Cleanup old WAL files
$ pg_archivecleanup /backup/wal 000000010000000000000010

5. Point-in-Time Recovery (PITR)

Stop PostgreSQL
$ sudo systemctl stop postgresql

Remove current data
$ rm -rf /var/lib/postgresql/data/*

Restore base backup
$ tar -xf /backup/base/base.tar -C /var/lib/postgresql/data/

Create recovery configuration
$ cat > /var/lib/postgresql/data/recovery.signal << EOF
restore_command = 'cp /backup/wal/%f %p'
recovery_target_time = '2024-01-15 14:30:00'
EOF

Start PostgreSQL
$ sudo systemctl start postgresql

Recovery targeting options
postgres=# recovery_target_time = '2024-01-15 14:30:00'
postgres=# recovery_target_xid = '12345'
postgres=# recovery_target_name = 'before_data_migration'

Create named restore point
postgres=# SELECT pg_create_restore_point('before_data_migration');
